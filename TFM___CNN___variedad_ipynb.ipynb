{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JALVARADORUIZ/TFM_UB/blob/main/TFM___CNN___variedad_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFEF-Ak-cH5_",
        "outputId": "a50949fa-783d-4eee-b73e-3e564dd72914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "dim = 100"
      ],
      "metadata": {
        "id": "62UQPUdncI42"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/drive/MyDrive/TFM_Máster BDDS/datawine/df_img_processed2.csv'\n",
        "df = pd.read_csv(data)"
      ],
      "metadata": {
        "id": "t2uVdJmJdN_N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[0:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esuDC-3rdhTM",
        "outputId": "83ba1ee6-6b62-42c5-b8c9-5b68acd260b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['winery', 'product', 'region', 'country_code', 'rating', 'variety',\n",
              "       'price_usd', 'image', 'continente', 'country_code_clean', 'price_cat',\n",
              "       'rating_cat', 'quality', 'color', 'image_clean'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def getFeatures(files):\n",
        "    images = []\n",
        "    path = \"/content/drive/MyDrive/TFM_Máster BDDS/datawine/vintage-images/\"\n",
        "    for f in enumerate(files):\n",
        "        #print(f[1])\n",
        "        image_path = path + f[1]\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        image = cv2.resize(image, (dim, dim))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        images.append(image)\n",
        "    return images\n",
        "\n",
        "X = getFeatures(df['image_clean'])\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "k_eG0TnAsxXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open('/content/drive/MyDrive/TFM_Máster BDDS/100_features.npy', 'wb') as f:\n",
        "    np.save(f, X)\n",
        "'''"
      ],
      "metadata": {
        "id": "OyUdNvF7Kcw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TFM_Máster BDDS/100_features.npy', 'rb') as f:\n",
        "    X= np.load(f)"
      ],
      "metadata": {
        "id": "zglrzlepLsot"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy5F3afyvAWQ",
        "outputId": "f8c2fb22-de51-4603-86b6-bce117d77d2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9878, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_variety = df['variety'].value_counts().rename_axis('variety').to_frame('counts')\n",
        "df_variety_selected = df_variety[:15]\n",
        "list_variety = list(df_variety_selected.index)\n",
        "\n",
        "def transform_variety(variety, list_variety):\n",
        "  if variety in list_variety:\n",
        "    return variety\n",
        "  else:\n",
        "    return \"other\"\n",
        "\n",
        "df['variety'] = df.progress_apply(lambda x:transform_variety(x.variety,list_variety), axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "variedad = le.fit_transform(df['variety'])\n",
        "y = np.array(variedad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIlppIhpvyKt",
        "outputId": "7217e9b3-9115-4941-bf20-f67ab1377039"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9878/9878 [00:02<00:00, 4475.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JUjnIG01MbX",
        "outputId": "4d5b971d-0372-4cde-f139-f0e7295824d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9878,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
      ],
      "metadata": {
        "id": "aarFgbf20xAy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "metadata": {
        "id": "BF6aO4yXDyGx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probando Red neuronal Convulsional Simple (Sin Dropout)**"
      ],
      "metadata": {
        "id": "T65SgUzEOKqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import the data set from tensorflow and build the model there\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(16))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRE1mQ9bClZU",
        "outputId": "24d04148-4687-4678-ced3-8663a9aff14b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 49, 49, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 28224)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                1806400   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,863,760\n",
            "Trainable params: 1,863,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "YOiQ2N3fCxnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d883638b-b459-440d-a462-32932ca63068"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "217/217 [==============================] - 5s 19ms/step - loss: 2.1874 - accuracy: 0.3248 - val_loss: 2.0789 - val_accuracy: 0.3721\n",
            "Epoch 2/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 1.9235 - accuracy: 0.3972 - val_loss: 1.9601 - val_accuracy: 0.3883\n",
            "Epoch 3/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 1.7782 - accuracy: 0.4319 - val_loss: 1.8383 - val_accuracy: 0.4231\n",
            "Epoch 4/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 1.6156 - accuracy: 0.4829 - val_loss: 1.7950 - val_accuracy: 0.4413\n",
            "Epoch 5/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 1.3637 - accuracy: 0.5597 - val_loss: 1.8130 - val_accuracy: 0.4514\n",
            "Epoch 6/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 1.0590 - accuracy: 0.6582 - val_loss: 2.0225 - val_accuracy: 0.4831\n",
            "Epoch 7/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.7881 - accuracy: 0.7433 - val_loss: 2.2627 - val_accuracy: 0.4949\n",
            "Epoch 8/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.4938 - accuracy: 0.8390 - val_loss: 2.5688 - val_accuracy: 0.4899\n",
            "Epoch 9/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.3061 - accuracy: 0.9050 - val_loss: 3.1170 - val_accuracy: 0.4801\n",
            "Epoch 10/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.1842 - accuracy: 0.9447 - val_loss: 3.5264 - val_accuracy: 0.5067\n",
            "Epoch 11/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.1117 - accuracy: 0.9673 - val_loss: 4.0095 - val_accuracy: 0.4980\n",
            "Epoch 12/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0909 - accuracy: 0.9741 - val_loss: 4.0478 - val_accuracy: 0.4990\n",
            "Epoch 13/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0643 - accuracy: 0.9808 - val_loss: 4.8471 - val_accuracy: 0.4963\n",
            "Epoch 14/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0797 - accuracy: 0.9776 - val_loss: 4.8325 - val_accuracy: 0.5061\n",
            "Epoch 15/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 4.6289 - val_accuracy: 0.4993\n",
            "Epoch 16/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0420 - accuracy: 0.9900 - val_loss: 4.9055 - val_accuracy: 0.5047\n",
            "Epoch 17/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 5.3774 - val_accuracy: 0.4949\n",
            "Epoch 18/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 4.8894 - val_accuracy: 0.4993\n",
            "Epoch 19/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 5.1384 - val_accuracy: 0.4953\n",
            "Epoch 20/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0375 - accuracy: 0.9889 - val_loss: 5.0501 - val_accuracy: 0.5040\n",
            "Epoch 21/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 5.8950 - val_accuracy: 0.5030\n",
            "Epoch 22/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0539 - accuracy: 0.9821 - val_loss: 5.2915 - val_accuracy: 0.4980\n",
            "Epoch 23/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0703 - accuracy: 0.9783 - val_loss: 5.3737 - val_accuracy: 0.4956\n",
            "Epoch 24/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 5.4714 - val_accuracy: 0.5027\n",
            "Epoch 25/30\n",
            "217/217 [==============================] - 3s 16ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 6.1422 - val_accuracy: 0.4983\n",
            "Epoch 26/30\n",
            "217/217 [==============================] - 4s 17ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 6.4474 - val_accuracy: 0.5071\n",
            "Epoch 27/30\n",
            "217/217 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 6.7065 - val_accuracy: 0.5078\n",
            "Epoch 28/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 9.8516e-04 - accuracy: 0.9997 - val_loss: 6.8700 - val_accuracy: 0.5064\n",
            "Epoch 29/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 8.5399e-04 - accuracy: 0.9997 - val_loss: 7.0106 - val_accuracy: 0.5064\n",
            "Epoch 30/30\n",
            "217/217 [==============================] - 3s 15ms/step - loss: 6.4284e-04 - accuracy: 0.9997 - val_loss: 7.0682 - val_accuracy: 0.5057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6EB0eC3UECgk",
        "outputId": "30374bec-1593-4390-8d8e-5ed5ebeef426"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5cda244850>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Red Neuronal Convulsional con Dropout**"
      ],
      "metadata": {
        "id": "vPOC57e_OVkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#### Input Layer ####\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
        "                 activation='relu', input_shape=(100, 100, 3)))\n",
        "\n",
        "#### Convolutional Layers ####\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))  # Pooling\n",
        "model.add(Dropout(0.2)) # Dropout\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#### Fully-Connected Layer ####\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "\n",
        "model.summary() # a handy way to inspect the architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJYYN_-QHdfX",
        "outputId": "6f12198e-06ec-4e79-d25e-481858c0014e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 100, 100, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 98, 98, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 49, 49, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 49, 49, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 47, 47, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 23, 23, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 23, 23, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 21, 21, 128)       147584    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 21, 21, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 10, 10, 512)       1638912   \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 512)         6554112   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                16400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,021,744\n",
            "Trainable params: 9,021,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001), \n",
        "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, \n",
        "                    validation_data=(X_test, y_test))\n",
        "'''"
      ],
      "metadata": {
        "id": "_t8vlH_-HpMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "'''"
      ],
      "metadata": {
        "id": "dg0ogPJPKcwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "'''import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import datasets, layers, models'''\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "#from livelossplot import PlotLossesKeras\n",
        "#from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
        "val_steps = y_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Saves Keras model after each epoch\n",
        "checkpointer = ModelCheckpoint(filepath='img_model.weights.best.hdf5', \n",
        "                               verbose=1, \n",
        "                               save_best_only=True)\n",
        "\n",
        "# Early stopping to prevent overtraining and to ensure decreasing validation loss\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')\n",
        "\n",
        "# tensorboard_callback = TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "# Actual fitting of the model\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=n_epochs, \n",
        "                    #steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    #validation_steps=val_steps,\n",
        "                    callbacks=[checkpointer],\n",
        "                    verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDffXgcaIRK5",
        "outputId": "a9d7cd35-174e-4040-f6c3-a2db0eba51e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217/217 [==============================] - ETA: 0s - loss: 2.4247 - accuracy: 0.2223\n",
            "Epoch 1: val_loss improved from inf to 2.37618, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 28s 70ms/step - loss: 2.4247 - accuracy: 0.2223 - val_loss: 2.3762 - val_accuracy: 0.2763\n",
            "Epoch 2/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 2.2429 - accuracy: 0.2925\n",
            "Epoch 2: val_loss improved from 2.37618 to 2.29461, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 2.2427 - accuracy: 0.2926 - val_loss: 2.2946 - val_accuracy: 0.2470\n",
            "Epoch 3/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 2.0726 - accuracy: 0.3410\n",
            "Epoch 3: val_loss improved from 2.29461 to 2.17478, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 2.0723 - accuracy: 0.3412 - val_loss: 2.1748 - val_accuracy: 0.3327\n",
            "Epoch 4/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 2.0126 - accuracy: 0.3587\n",
            "Epoch 4: val_loss improved from 2.17478 to 2.01838, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 66ms/step - loss: 2.0126 - accuracy: 0.3587 - val_loss: 2.0184 - val_accuracy: 0.3688\n",
            "Epoch 5/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.9883 - accuracy: 0.3679\n",
            "Epoch 5: val_loss did not improve from 2.01838\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.9883 - accuracy: 0.3679 - val_loss: 2.1477 - val_accuracy: 0.3512\n",
            "Epoch 6/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.9521 - accuracy: 0.3786\n",
            "Epoch 6: val_loss improved from 2.01838 to 1.98911, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 65ms/step - loss: 1.9521 - accuracy: 0.3787 - val_loss: 1.9891 - val_accuracy: 0.3715\n",
            "Epoch 7/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.9257 - accuracy: 0.3777\n",
            "Epoch 7: val_loss did not improve from 1.98911\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.9261 - accuracy: 0.3776 - val_loss: 2.0540 - val_accuracy: 0.3856\n",
            "Epoch 8/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.8979 - accuracy: 0.3870\n",
            "Epoch 8: val_loss improved from 1.98911 to 1.94769, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.8980 - accuracy: 0.3869 - val_loss: 1.9477 - val_accuracy: 0.3772\n",
            "Epoch 9/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.8710 - accuracy: 0.3945\n",
            "Epoch 9: val_loss improved from 1.94769 to 1.94211, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.8710 - accuracy: 0.3946 - val_loss: 1.9421 - val_accuracy: 0.3930\n",
            "Epoch 10/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.8343 - accuracy: 0.4013\n",
            "Epoch 10: val_loss did not improve from 1.94211\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.8354 - accuracy: 0.4012 - val_loss: 2.0640 - val_accuracy: 0.3904\n",
            "Epoch 11/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.7902 - accuracy: 0.4162\n",
            "Epoch 11: val_loss did not improve from 1.94211\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.7904 - accuracy: 0.4163 - val_loss: 2.0956 - val_accuracy: 0.3131\n",
            "Epoch 12/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.7545 - accuracy: 0.4266\n",
            "Epoch 12: val_loss did not improve from 1.94211\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.7544 - accuracy: 0.4267 - val_loss: 1.9938 - val_accuracy: 0.3414\n",
            "Epoch 13/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.7103 - accuracy: 0.4374\n",
            "Epoch 13: val_loss improved from 1.94211 to 1.81724, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.7101 - accuracy: 0.4374 - val_loss: 1.8172 - val_accuracy: 0.4261\n",
            "Epoch 14/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.6521 - accuracy: 0.4540\n",
            "Epoch 14: val_loss did not improve from 1.81724\n",
            "217/217 [==============================] - 15s 67ms/step - loss: 1.6526 - accuracy: 0.4540 - val_loss: 1.8969 - val_accuracy: 0.3715\n",
            "Epoch 15/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.6031 - accuracy: 0.4763\n",
            "Epoch 15: val_loss did not improve from 1.81724\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.6033 - accuracy: 0.4763 - val_loss: 1.8678 - val_accuracy: 0.4096\n",
            "Epoch 16/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.5335 - accuracy: 0.4932\n",
            "Epoch 16: val_loss did not improve from 1.81724\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.5336 - accuracy: 0.4932 - val_loss: 1.8957 - val_accuracy: 0.4116\n",
            "Epoch 17/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.4508 - accuracy: 0.5166\n",
            "Epoch 17: val_loss did not improve from 1.81724\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.4506 - accuracy: 0.5166 - val_loss: 1.8711 - val_accuracy: 0.4339\n",
            "Epoch 18/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.3743 - accuracy: 0.5447\n",
            "Epoch 18: val_loss improved from 1.81724 to 1.75684, saving model to img_model.weights.best.hdf5\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 1.3743 - accuracy: 0.5447 - val_loss: 1.7568 - val_accuracy: 0.4524\n",
            "Epoch 19/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.2729 - accuracy: 0.5816\n",
            "Epoch 19: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.2728 - accuracy: 0.5816 - val_loss: 1.7676 - val_accuracy: 0.4399\n",
            "Epoch 20/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.1738 - accuracy: 0.6102\n",
            "Epoch 20: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.1742 - accuracy: 0.6101 - val_loss: 1.9731 - val_accuracy: 0.4153\n",
            "Epoch 21/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 1.0807 - accuracy: 0.6386\n",
            "Epoch 21: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 1.0805 - accuracy: 0.6387 - val_loss: 2.1041 - val_accuracy: 0.4410\n",
            "Epoch 22/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.9737 - accuracy: 0.6755\n",
            "Epoch 22: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.9734 - accuracy: 0.6756 - val_loss: 1.7880 - val_accuracy: 0.4953\n",
            "Epoch 23/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.8691 - accuracy: 0.7128\n",
            "Epoch 23: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.8692 - accuracy: 0.7128 - val_loss: 2.0489 - val_accuracy: 0.4760\n",
            "Epoch 24/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.7535 - accuracy: 0.7514\n",
            "Epoch 24: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.7534 - accuracy: 0.7515 - val_loss: 2.1132 - val_accuracy: 0.4676\n",
            "Epoch 25/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.7695\n",
            "Epoch 25: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.6718 - accuracy: 0.7695 - val_loss: 2.6134 - val_accuracy: 0.4109\n",
            "Epoch 26/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.5621 - accuracy: 0.8119\n",
            "Epoch 26: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.5620 - accuracy: 0.8120 - val_loss: 2.5612 - val_accuracy: 0.4912\n",
            "Epoch 27/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.8393\n",
            "Epoch 27: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.4886 - accuracy: 0.8393 - val_loss: 3.2330 - val_accuracy: 0.3623\n",
            "Epoch 28/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.4192 - accuracy: 0.8555\n",
            "Epoch 28: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.4192 - accuracy: 0.8555 - val_loss: 2.8434 - val_accuracy: 0.4464\n",
            "Epoch 29/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.3630 - accuracy: 0.8673\n",
            "Epoch 29: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.3631 - accuracy: 0.8672 - val_loss: 2.8586 - val_accuracy: 0.4798\n",
            "Epoch 30/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.3164 - accuracy: 0.8929\n",
            "Epoch 30: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.3163 - accuracy: 0.8930 - val_loss: 2.7339 - val_accuracy: 0.4862\n",
            "Epoch 31/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.9087\n",
            "Epoch 31: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.2800 - accuracy: 0.9087 - val_loss: 3.3952 - val_accuracy: 0.5118\n",
            "Epoch 32/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9197\n",
            "Epoch 32: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.2500 - accuracy: 0.9197 - val_loss: 2.8414 - val_accuracy: 0.4990\n",
            "Epoch 33/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9194\n",
            "Epoch 33: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.2264 - accuracy: 0.9194 - val_loss: 3.2259 - val_accuracy: 0.4987\n",
            "Epoch 34/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9308\n",
            "Epoch 34: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.2037 - accuracy: 0.9309 - val_loss: 3.3652 - val_accuracy: 0.5024\n",
            "Epoch 35/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.9401\n",
            "Epoch 35: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1913 - accuracy: 0.9400 - val_loss: 3.1882 - val_accuracy: 0.4804\n",
            "Epoch 36/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9440\n",
            "Epoch 36: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1704 - accuracy: 0.9440 - val_loss: 3.2938 - val_accuracy: 0.4922\n",
            "Epoch 37/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9427\n",
            "Epoch 37: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1664 - accuracy: 0.9427 - val_loss: 3.7519 - val_accuracy: 0.4639\n",
            "Epoch 38/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9492\n",
            "Epoch 38: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1539 - accuracy: 0.9492 - val_loss: 3.4052 - val_accuracy: 0.4946\n",
            "Epoch 39/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9565\n",
            "Epoch 39: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.1431 - accuracy: 0.9565 - val_loss: 3.4325 - val_accuracy: 0.4980\n",
            "Epoch 40/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9512\n",
            "Epoch 40: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1470 - accuracy: 0.9513 - val_loss: 3.5103 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9579\n",
            "Epoch 41: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1253 - accuracy: 0.9579 - val_loss: 3.8378 - val_accuracy: 0.4983\n",
            "Epoch 42/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.9617\n",
            "Epoch 42: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 3.7272 - val_accuracy: 0.4848\n",
            "Epoch 43/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9618\n",
            "Epoch 43: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1183 - accuracy: 0.9618 - val_loss: 3.4247 - val_accuracy: 0.5061\n",
            "Epoch 44/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9654\n",
            "Epoch 44: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1141 - accuracy: 0.9654 - val_loss: 3.7812 - val_accuracy: 0.5027\n",
            "Epoch 45/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9660\n",
            "Epoch 45: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1058 - accuracy: 0.9660 - val_loss: 4.0884 - val_accuracy: 0.5091\n",
            "Epoch 46/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9670\n",
            "Epoch 46: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0997 - accuracy: 0.9670 - val_loss: 4.2006 - val_accuracy: 0.5159\n",
            "Epoch 47/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9628\n",
            "Epoch 47: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1201 - accuracy: 0.9628 - val_loss: 3.6951 - val_accuracy: 0.4831\n",
            "Epoch 48/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9701\n",
            "Epoch 48: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0930 - accuracy: 0.9701 - val_loss: 3.9646 - val_accuracy: 0.5040\n",
            "Epoch 49/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9701\n",
            "Epoch 49: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0932 - accuracy: 0.9701 - val_loss: 4.3348 - val_accuracy: 0.4960\n",
            "Epoch 50/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9689\n",
            "Epoch 50: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.0930 - accuracy: 0.9689 - val_loss: 3.9333 - val_accuracy: 0.4993\n",
            "Epoch 51/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9714\n",
            "Epoch 51: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0946 - accuracy: 0.9714 - val_loss: 4.0807 - val_accuracy: 0.5135\n",
            "Epoch 52/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9748\n",
            "Epoch 52: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0838 - accuracy: 0.9748 - val_loss: 3.6711 - val_accuracy: 0.4926\n",
            "Epoch 53/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 0.9722\n",
            "Epoch 53: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0903 - accuracy: 0.9722 - val_loss: 4.4195 - val_accuracy: 0.5148\n",
            "Epoch 54/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9719\n",
            "Epoch 54: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0972 - accuracy: 0.9719 - val_loss: 4.0706 - val_accuracy: 0.5145\n",
            "Epoch 55/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9744\n",
            "Epoch 55: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0780 - accuracy: 0.9744 - val_loss: 5.0387 - val_accuracy: 0.5159\n",
            "Epoch 56/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9729\n",
            "Epoch 56: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0953 - accuracy: 0.9730 - val_loss: 4.3854 - val_accuracy: 0.5105\n",
            "Epoch 57/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9761\n",
            "Epoch 57: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0707 - accuracy: 0.9761 - val_loss: 4.8357 - val_accuracy: 0.5148\n",
            "Epoch 58/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9755\n",
            "Epoch 58: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 4.6641 - val_accuracy: 0.5074\n",
            "Epoch 59/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9745\n",
            "Epoch 59: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0831 - accuracy: 0.9745 - val_loss: 4.8572 - val_accuracy: 0.5037\n",
            "Epoch 60/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9764\n",
            "Epoch 60: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0799 - accuracy: 0.9764 - val_loss: 4.8787 - val_accuracy: 0.5108\n",
            "Epoch 61/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9763\n",
            "Epoch 61: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.0749 - accuracy: 0.9763 - val_loss: 4.4300 - val_accuracy: 0.4811\n",
            "Epoch 62/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9747\n",
            "Epoch 62: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 4.5603 - val_accuracy: 0.4976\n",
            "Epoch 63/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 0.9745\n",
            "Epoch 63: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0868 - accuracy: 0.9745 - val_loss: 4.4538 - val_accuracy: 0.4926\n",
            "Epoch 64/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9753\n",
            "Epoch 64: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 4.0535 - val_accuracy: 0.4821\n",
            "Epoch 65/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9735\n",
            "Epoch 65: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0919 - accuracy: 0.9735 - val_loss: 4.0598 - val_accuracy: 0.5030\n",
            "Epoch 66/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9734\n",
            "Epoch 66: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 15s 68ms/step - loss: 0.0876 - accuracy: 0.9734 - val_loss: 4.2712 - val_accuracy: 0.4912\n",
            "Epoch 67/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9774\n",
            "Epoch 67: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0841 - accuracy: 0.9774 - val_loss: 4.1331 - val_accuracy: 0.5061\n",
            "Epoch 68/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9769\n",
            "Epoch 68: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0796 - accuracy: 0.9769 - val_loss: 4.2316 - val_accuracy: 0.4987\n",
            "Epoch 69/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9754\n",
            "Epoch 69: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0891 - accuracy: 0.9754 - val_loss: 4.6238 - val_accuracy: 0.4879\n",
            "Epoch 70/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9738\n",
            "Epoch 70: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0904 - accuracy: 0.9738 - val_loss: 3.3288 - val_accuracy: 0.4841\n",
            "Epoch 71/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9770\n",
            "Epoch 71: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0780 - accuracy: 0.9770 - val_loss: 4.7452 - val_accuracy: 0.4993\n",
            "Epoch 72/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9770\n",
            "Epoch 72: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.0838 - accuracy: 0.9770 - val_loss: 5.4933 - val_accuracy: 0.5142\n",
            "Epoch 73/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9755\n",
            "Epoch 73: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0872 - accuracy: 0.9756 - val_loss: 4.7692 - val_accuracy: 0.5098\n",
            "Epoch 74/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9784\n",
            "Epoch 74: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 4.4684 - val_accuracy: 0.5094\n",
            "Epoch 75/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9740\n",
            "Epoch 75: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0888 - accuracy: 0.9740 - val_loss: 5.1635 - val_accuracy: 0.5121\n",
            "Epoch 76/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9771\n",
            "Epoch 76: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0768 - accuracy: 0.9771 - val_loss: 4.9541 - val_accuracy: 0.5007\n",
            "Epoch 77/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9734\n",
            "Epoch 77: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0850 - accuracy: 0.9734 - val_loss: 5.2303 - val_accuracy: 0.4848\n",
            "Epoch 78/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9750\n",
            "Epoch 78: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0949 - accuracy: 0.9750 - val_loss: 4.4258 - val_accuracy: 0.4926\n",
            "Epoch 79/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9779\n",
            "Epoch 79: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 15s 68ms/step - loss: 0.0874 - accuracy: 0.9779 - val_loss: 5.0051 - val_accuracy: 0.5037\n",
            "Epoch 80/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9750\n",
            "Epoch 80: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0896 - accuracy: 0.9748 - val_loss: 3.8741 - val_accuracy: 0.4443\n",
            "Epoch 81/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9770\n",
            "Epoch 81: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0889 - accuracy: 0.9770 - val_loss: 4.4986 - val_accuracy: 0.5054\n",
            "Epoch 82/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9734\n",
            "Epoch 82: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0828 - accuracy: 0.9734 - val_loss: 5.0804 - val_accuracy: 0.4926\n",
            "Epoch 83/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9737\n",
            "Epoch 83: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.0947 - accuracy: 0.9737 - val_loss: 4.2344 - val_accuracy: 0.5054\n",
            "Epoch 84/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9771\n",
            "Epoch 84: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0856 - accuracy: 0.9771 - val_loss: 3.4378 - val_accuracy: 0.4990\n",
            "Epoch 85/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9750\n",
            "Epoch 85: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0863 - accuracy: 0.9748 - val_loss: 5.1430 - val_accuracy: 0.5030\n",
            "Epoch 86/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9747\n",
            "Epoch 86: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0946 - accuracy: 0.9747 - val_loss: 4.3624 - val_accuracy: 0.4919\n",
            "Epoch 87/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9676\n",
            "Epoch 87: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1030 - accuracy: 0.9676 - val_loss: 4.7280 - val_accuracy: 0.4973\n",
            "Epoch 88/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9747\n",
            "Epoch 88: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0980 - accuracy: 0.9747 - val_loss: 3.8146 - val_accuracy: 0.4760\n",
            "Epoch 89/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9758\n",
            "Epoch 89: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 4.4963 - val_accuracy: 0.4980\n",
            "Epoch 90/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9742\n",
            "Epoch 90: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0993 - accuracy: 0.9743 - val_loss: 5.5186 - val_accuracy: 0.4855\n",
            "Epoch 91/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9727\n",
            "Epoch 91: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 5.0809 - val_accuracy: 0.4939\n",
            "Epoch 92/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9757\n",
            "Epoch 92: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0943 - accuracy: 0.9757 - val_loss: 4.4784 - val_accuracy: 0.4919\n",
            "Epoch 93/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9770\n",
            "Epoch 93: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0978 - accuracy: 0.9770 - val_loss: 4.7818 - val_accuracy: 0.5078\n",
            "Epoch 94/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9724\n",
            "Epoch 94: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 64ms/step - loss: 0.1010 - accuracy: 0.9724 - val_loss: 4.3832 - val_accuracy: 0.4997\n",
            "Epoch 95/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9744\n",
            "Epoch 95: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1059 - accuracy: 0.9744 - val_loss: 4.2296 - val_accuracy: 0.5013\n",
            "Epoch 96/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9761\n",
            "Epoch 96: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0841 - accuracy: 0.9760 - val_loss: 3.9521 - val_accuracy: 0.4963\n",
            "Epoch 97/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9782\n",
            "Epoch 97: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0831 - accuracy: 0.9782 - val_loss: 5.3320 - val_accuracy: 0.5165\n",
            "Epoch 98/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9754\n",
            "Epoch 98: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0909 - accuracy: 0.9754 - val_loss: 4.1624 - val_accuracy: 0.4963\n",
            "Epoch 99/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9728\n",
            "Epoch 99: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.0907 - accuracy: 0.9728 - val_loss: 4.8584 - val_accuracy: 0.5037\n",
            "Epoch 100/100\n",
            "216/217 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9709\n",
            "Epoch 100: val_loss did not improve from 1.75684\n",
            "217/217 [==============================] - 14s 63ms/step - loss: 0.1065 - accuracy: 0.9709 - val_loss: 5.1781 - val_accuracy: 0.5138\n",
            "CPU times: user 16min 47s, sys: 45.9 s, total: 17min 33s\n",
            "Wall time: 23min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'][97],history.history['loss'][97]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaxgL51fedkq",
        "outputId": "fde5123f-9154-46ca-ef3d-356919814cba"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9795918464660645, 0.08132734149694443)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['val_accuracy'],history.history['val_loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFYkg8-lfWN5",
        "outputId": "159c0496-1e60-480a-cfec-08497b2753ac"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.27732792496681213], [2.4365451335906982])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_XSiIcmTbmTb",
        "outputId": "54aee9fb-cb9d-4b0f-9af9-fe59219d2529"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd8bf7ed050>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 10])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oQjg4wUGbsA1",
        "outputId": "e9bc9398-5a87-471f-bf5a-0eeee9c470a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd8be757e90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3yU5Z3//9dnJpNzSEIgCSThpJwFT8h6aKmKWs+H+m3R1baed63art3V2tbut2u73W9bf+1uW0urPahda7XYA+3qWqsoWrUSEZCDIGcSTiGQkJDz5PP7YwYaIEAiGSaZ+/18PPJg7nvu3PO5GZj33Nd13ddt7o6IiARXKNkFiIhIcikIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BIWBGb2MzPbbmZLD/G8mdn3zGy1mS0xs1MSVYuIiBxaIs8IHgUuPMzzFwFj4z+3AbMTWIuIiBxCwoLA3ecDOw+zyRXA4x7zJlBgZsMSVY+IiHQvLYmvXQZs6rJcFV+35cANzew2YmcN5OTknDphwoRjUmAq2bSziaa2KONL85Jdiogkwdtvv73D3Yd291wyg6DH3P1h4GGAadOmeWVlZZIrGngefH4ls19Zw5tfu5C0sMYIiASNmW041HPJ/ESoBiq6LJfH10kCjBicTbTT2VLfkuxSRKSfSWYQzAU+FR89dDpQ7+4HNQtJ36gYnA3Axp1NSa5ERPqbhDUNmdmTwNnAEDOrAv4vEAFw9x8BzwIXA6uBJuDGRNUiMKLob0FwVpJrEZH+JWFB4O7XHuF5B+5I1OvL/koHZRIJm84IROQg6jUMiHDIKC/MVhCIyEEUBAFSMTibjbUKAhHZn4IgQEYO1hmBiBxMQRAgI4uyqW9up76pPdmliEg/oiAIkL1DSDfs3JPkSkSkP1EQBMjI+BDSDeonEJEuFAQBMkIXlYlINxQEAZKdnsaQ3AyNHBKR/SgIAmZkUbb6CERkPwqCgBk5OJtNO5uTXYaI9CMKgoAZUZTN5vpmWjuiyS5FRPoJBUHAjBicjTtU7dJZgYjEKAgCZu8QUnUYi8heCoKAGTE4B9AQUhH5GwVBwAzJTSc7PayLykRkHwVBwJgZIwZns1FDSEUkTkEQQCM0C6mIdKEgCKCRRbEgiN0kTkSCTkEQQCOKcmhp72R7Q2uySxGRfkBBEEB7J59Th7GIgIIgkEZqFlIR6UJBEEBlhVmEDDbWauSQiCgIAikSDjG8IIsNOiMQERQEgVVRmK35hkQEUBAEVllhFtUKAhFBQRBY5YVZbGtooa2jM9mliEiSKQgCqqwgC3fYUq+zApGgUxAEVFlhFoCah0REQRBU5QWxawmq6hQEIkGnIAio0vxMzHRGICIKgsBKTwtROihTQ0hFREEQZGUFWVTX6aIykaBTEARYWWEW1eojEAk8BUGAlRVksaWuhWin7ksgEmQKggArL8ymo9PZtrsl2aWISBIlNAjM7EIzW2lmq83svm6eH2Fm88zsHTNbYmYXJ7Ie2d++awnUPCQSaAkLAjMLAw8BFwGTgGvNbNIBm90PPO3uJwPXAD9MVD1ysLICXVQmIok9I5gOrHb3te7eBvwKuOKAbRwYFH+cD2xOYD1ygL1BULVLI4dEgiyRQVAGbOqyXBVf19VXgevNrAp4Frirux2Z2W1mVmlmlTU1NYmoNZCy0sMMyU1X05BIwCW7s/ha4FF3LwcuBn5hZgfV5O4Pu/s0d582dOjQY15kKisryNJFZSIBl8ggqAYquiyXx9d1dTPwNIC7vwFkAkMSWJMcQNcSiEgig2ABMNbMRptZOrHO4LkHbLMRmAlgZhOJBYHafo6hsoLYDWrcdS2BSFAlLAjcvQO4E3geWEFsdNAyM3vAzC6Pb/bPwK1mthh4ErjB9Yl0TJUXZtPa0cmOxrZklyIiSZKWyJ27+7PEOoG7rvvXLo+XA2clsgY5vH1DSOuaGZqXkeRqRCQZkt1ZLEm296IyDSEVCS4FQcDpTmUioiAIuEGZEfIy0zRySCTAFARCeWG2riUQCTAFgTB6SDZraxqTXYaIJImCQBhXkseGnU00t0WTXYqIJIGCQBhfkoc7rN6uswKRIFIQCONL8wB4b+vuJFciIsmgIBBGFuWQnhZi1baGZJciIkmgIBDCIWNscS4rt6lpSCSIFAQCxJqHVqppSCSQFAQCxDqMt+1upa5Jk8+JBI2CQAAYF+8wXrlV/QQiQaMgEAAmxINAHcYiwaMgEABKB2WSl5nGSgWBSOAoCAQAM2N8SZ6ahkQCSEEg+8RGDjXotpUiAaMgkH3Gl+axu6WDbbtbk12KiBxDCgLZZ1yJppoQCSIFgewzvkQjh0SCSEEg+xTmpFOcl8HKrZpqQiRIFASyn/GleTojEAkYBYHsZ1RRDhtq9yS7DBE5hhQEsp+KwVnsbumgvrk92aWIyDGiIJD9VBRmA7BpZ1OSKxGRY0VBIPupGBwLgqpdCgKRoFAQyH7+dkbQnORKRORYURDIfvKzI+RlprFJZwQigaEgkINUFGarj0AkQBQEcpCKwVls2qWmIZGgUBDIQSoKs6na1aRZSEUCQkEgBykvzKKlvZOaRs1CKhIECgI5yN4hpBo5JBIMCgI5iK4lEAmWhAaBmV1oZivNbLWZ3XeIbT5hZsvNbJmZ/TKR9UjPlBdmAbq6WCQo0hK1YzMLAw8B5wNVwAIzm+vuy7tsMxb4InCWu+8ys+JE1SM9l52expDcdDUNiQREIs8IpgOr3X2tu7cBvwKuOGCbW4GH3H0XgLtvT2A90gvlhdm6qEwkIBIZBGXApi7LVfF1XY0DxpnZX8zsTTO7sLsdmdltZlZpZpU1NTUJKle6qhisIBAJimR3FqcBY4GzgWuBR8ys4MCN3P1hd5/m7tOGDh16jEsMporCLDbXtdAR7Ux2KSKSYEcMAjO7zMw+SGBUAxVdlsvj67qqAua6e7u7rwNWEQsGSbKKwdlEO50t9S3JLkVEEqwnH/CzgPfN7FtmNqEX+14AjDWz0WaWDlwDzD1gm98ROxvAzIYQaypa24vXkATZNwupmodEUt4Rg8DdrwdOBtYAj5rZG/E2+7wj/F4HcCfwPLACeNrdl5nZA2Z2eXyz54FaM1sOzAPucffaozge6SMVg2NDSKs0ckgk5fVo+Ki77zazOUAW8E/AVcA9ZvY9d//+YX7vWeDZA9b9a5fHDnw+/iP9yPCCLEKmMwKRIOhJH8HlZvZb4GUgAkx394uAE4F/Tmx5kiyRcIhh+Vm6qEwkAHpyRnA18F13n991pbs3mdnNiSlL+oPyQk1HLRIEPeks/irw1t4FM8sys1EA7v5iQqqSfmHE4Gw21OqMQCTV9SQIfg10HUweja+TFDe+NI8dja1sb9AQUpFU1pMgSItPEQFA/HF64kqS/mLy8HwAlm3eneRKRCSRehIENV2Ge2JmVwA7EleS9BeThg8CYLmCQCSl9aSz+B+BJ8zsB4ARmz/oUwmtSvqF/KwIIwZns2xzfbJLEZEEOmIQuPsa4HQzy40vNya8Kuk3Jg8fpKYhkRTXowvKzOwSYDKQaWYAuPsDCaxL+okTyvJ5bulWdre0MygzkuxyRCQBenJB2Y+IzTd0F7GmoY8DIxNcl/QT6icQSX096Sw+090/Bexy938DziA2OZwEwOR4EKh5SCR19SQI9g4ibzKz4UA7MCxxJUl/UpyXSXFehjqMRVJYT/oI/hC/Wcy3gYWAA48ktCrpVyYPH8Syap0RiKSqwwZB/IY0L7p7HfCMmf0RyHR3fT0MkMnD85n//g5a2qNkRsLJLkdE+thhm4bcvRN4qMtyq0IgeE4oG0S001m5tSHZpYhIAvSkj+BFM7va9o4blcDRVBMiqa0nQfAPxCaZazWz3WbWYGb6RAiQ8sIsBmWmsVQdxiIpqSdXFh/2lpSS+syMycPzdUYgkqKOGARmNqO79QfeqEZS2+Thg/jFmxvoiHaSFu7JiaSIDBQ9GT56T5fHmcB04G3g3IRUJP3SlPJ8Wjs6eX97IxOHDUp2OSLSh3rSNHRZ12UzqwD+M2EVSb80tbwAgHer6hUEIinmg5zjVwET+7oQ6d9GDs4mLzONxVV1yS5FRPpYT/oIvk/samKIBcdJxK4wlgAJhYwpZfm8W62RQyKppid9BJVdHncAT7r7XxJUj/RjU8rz+dlr62jtiJKRpiuMRVJFT4JgDtDi7lEAMwubWba7NyW2NOlvTiwvoD3qrNrayJTy/GSXIyJ9pEdXFgNZXZazgD8nphzpz6aUxT78l1Srn0AklfQkCDK73p4y/jg7cSVJf1VemEVhdoR3q9RPIJJKehIEe8zslL0LZnYq0Jy4kqS/MjOmlBewWEEgklJ60kfwT8CvzWwzsVtVlhK7daUE0NSyfGa/skZTUoukkJ5cULbAzCYA4+OrVrp7e2LLkv5qSnk+0U5n+ZbdnDKiMNnliEgf6MnN6+8Actx9qbsvBXLN7DOJL036oxO7XGEsIqmhJ30Et8bvUAaAu+8Cbk1cSdKflQzKYGheBksUBCIpoydBEO56UxozCwPpiStJ+jMzY2pZPu9qCKlIyuhJEPwv8JSZzTSzmcCTwHOJLUv6synl+by/vZGGFnUViaSCngTBF4CXgH+M/7zL/heYScBMHzUYd6hcvyvZpYhIHzhiEMRvYP9XYD2xexGcC6zoyc7N7EIzW2lmq83svsNsd7WZuZlN61nZkkynjCwkPRzizbW1yS5FRPrAIYePmtk44Nr4zw7gKQB3P6cnO473JTwEnE9s6uoFZjbX3ZcfsF0e8DliYSMDQGYkzEkjCnhDQSCSEg53RvAesW//l7r7h9z9+0C0F/ueDqx297Xu3gb8Criim+2+BnwTaOnFviXJTh9TxNLqenarn0BkwDtcEHwM2ALMM7NH4h3FdpjtD1QGbOqyXBVft0986ooKd/+fw+3IzG4zs0ozq6ypqelFCZIoZ4wpotNhwbqdyS5FRI7SIYPA3X/n7tcAE4B5xKaaKDaz2WZ2wdG+sJmFgO8A/3ykbd39YXef5u7Thg4derQvLX3g5BEFpKepn0AkFfSks3iPu/8yfu/icuAdYiOJjqQaqOiyXB5ft1cecALwspmtB04H5qrDeGDIjIQ5Rf0EIimhV/csdvdd8W/nM3uw+QJgrJmNNrN04Bpgbpd91bv7EHcf5e6jgDeBy929svvdSX9z+pgilm3eTX2z+glEBrIPcvP6HnH3DuBO4Hliw02fdvdlZvaAmV2eqNeVY+eMMUW4w1vqJxAZ0HoyDfUH5u7PAs8esO5fD7Ht2YmsRfreSSMKyEgL8caaWs6fVJLsckTkA0rYGYGkvoy0MKeOLFSHscgApyCQo3L6mCJWbN3Nrj1tyS5FRD4gBYEclRnjhuIOr6zS9R0iA5WCQI7K1LJ8huZl8MKKbckuRUQ+IAWBHJVQyJg5oZj5K2to6+hMdjki8gEoCOSozZxYQkNrBwvWaxipyECkIJCj9qHjh5CRFuKF5WoeEhmIFARy1LLSw3zo+CG8+N423D3Z5YhILykIpE/MnFjCpp3NrNrWmOxSRKSXFATSJ2ZOLAbgzxo9JDLgKAikT5QMymRqeT4vKghEBhwFgfSZmRNKeGdTHTUNrckuRUR6QUEgfebiKaW4w+8XVR95YxHpNxQE0mfGluRx8ogCnlqwSaOHRAYQBYH0qVnTKnh/eyPvbKpLdiki0kMKAulTl544nOz0ME+9tSnZpYhIDykIpE/lZqRx6dRh/GHJZhpbO5Jdjoj0gIJA+tys00bQ1Bblf5ZsTnYpItIDCgLpc6eMKOD44lx+tUDNQyIDgYJA+pyZcc1pFbyzsY73tu5OdjkicgQKAkmIq08pJysS5pH565JdiogcgYJAEqIwJ51rplfw+0XVVNc1J7scETkMBYEkzC0fHgPAI/PXJrkSETkcBYEkTFlBFleeXMavFmyktlHzD4n0VwoCSah//MgYWjs6efT19ckuRUQOQUEgCXV8cR4XTCrhsdfX6wIzkX5KQSAJ95mzj2d3SwcPv7Im2aWISDcUBJJwJ1YUcMVJw/nR/LWs37En2eWIyAEUBHJMfOniiURCxr/9YZmmqBbpZxQEckyUDMrk7vPHMW9lDX9esT3Z5YhIFwoCOWY+feYoxpXk8tW5y2huiya7HBGJUxDIMRMJh3jgihOormvmoXmrk12OiMQpCOSYOn1MER87uYwfz1/D6u0NyS5HRFAQSBJ8+ZKJ5GSk8aXfLKWzUx3HIsmW0CAwswvNbKWZrTaz+7p5/vNmttzMlpjZi2Y2MpH1SP9QlJvBFy+awFvrdzLn7apklyMSeAkLAjMLAw8BFwGTgGvNbNIBm70DTHP3qcAc4FuJqkf6l4+fWsFpowr5xnMrNA+RSJIl8oxgOrDa3de6exvwK+CKrhu4+zx3b4ovvgmUJ7Ae6UdCIePfr5rCntYObnp0ATUNCgORZElkEJQBXe9VWBVfdyg3A89194SZ3WZmlWZWWVNT04clSjKNK8lj9nWnsnJbAx+b/RfW1DQmuySRQOoXncVmdj0wDfh2d8+7+8PuPs3dpw0dOvTYFicJdd6kEn512xk0tUa5evbrLNpUl+ySRAInkUFQDVR0WS6Pr9uPmZ0HfBm43N3VPhBAJ1UU8NvPnEVuRhp3PLGQhpb2ZJckEiiJDIIFwFgzG21m6cA1wNyuG5jZycCPiYWA5h0IsBFF2fzXNSexpb6Zbzy7ItnliARKwoLA3TuAO4HngRXA0+6+zMweMLPL45t9G8gFfm1mi8xs7iF2JwFw6sjB3PrhMTz51iZeXqnvBSLHig20mSCnTZvmlZWVyS5DEqSlPcpl33+NhpYOnr97BvlZkWSXJP1Ee3s7VVVVtLS0JLuUfi0zM5Py8nIikf3/75jZ2+4+rbvfURBIv7Okqo6rfvg6pYMymTmxmBljh/KhsUPIjISTXZok0bp168jLy6OoqAgzS3Y5/ZK7U1tbS0NDA6NHj97vucMFQb8YNSTS1dTyAmZfdwoTSvP4dWUVtzxeycX/9Soba5uO/MuSslpaWhQCR2BmFBUV9fqsKS1B9YgclQsml3LB5FJaO6K8srKGe+Ys4WOz/8LPbjiNqeUFyS5PkkQhcGQf5O9IZwTSr2WkhblgcinP3H4mGWlhZv34TV5csS3ZZYmkFAWBDAjHF+fy2zvO5LjiHG55vJLvvLCKqGYulWMsNzc32SUkhJqGZMAozsvk1/9wJl/5/VK+9+L7LNywizvPPZ7K9TuZv2oHoRA8euN0dSqL9JKCQAaUrPQwD378RKaPGsxXfr+Uax5+E4AJpXm8t7WB7734PvdeOCHJVUqi/dsflrF88+4+3eek4YP4v5dN7tG27s69997Lc889h5lx//33M2vWLLZs2cKsWbPYvXs3HR0dzJ49mzPPPJObb76ZyspKzIybbrqJu+++u09rP1oKAhmQPnFaBaeOKmTl1gb+bvRginIzuOfXi/nx/LVcPGUYJ5TlJ7tESWG/+c1vWLRoEYsXL2bHjh2cdtppzJgxg1/+8pd89KMf5ctf/jLRaJSmpiYWLVpEdXU1S5cuBaCurv/Np6UgkAHruKG5HDf0b222918yiZdX1XDvnCX8/s6ziITVBZaqevrNPVFee+01rr32WsLhMCUlJXzkIx9hwYIFnHbaadx00020t7dz5ZVXctJJJzFmzBjWrl3LXXfdxSWXXMIFF1yQ1Nq7o/8pkjLysyN8/coTWL5lNz+ct4aBdrGkDHwzZsxg/vz5lJWVccMNN/D4449TWFjI4sWLOfvss/nRj37ELbfckuwyD6IgkJTy0cmlXDp1GN/98yrO/f9e4f899x6V63fS1NbxgfankUnSnQ9/+MM89dRTRKNRampqmD9/PtOnT2fDhg2UlJRw6623csstt7Bw4UJ27NhBZ2cnV199NV//+tdZuHBhsss/iJqGJOU8+PETOX1MEc8v28pPXl3Lj15ZgxmMKsph0rBBzBg3hHMmFFOcl3nY/WysbeLqH73OXecez6fOGHVsipcB4aqrruKNN97gxBNPxMz41re+RWlpKY899hjf/va3iUQi5Obm8vjjj1NdXc2NN95IZ2cnAP/xH/+R5OoPprmGJKXVN7XzxtpaVm5t4L2tu1m0qY4t9bHL70+qKOBz543lnPHFB/1etNOZ9eM3qNywi/ysCPPvPUcT4CXZihUrmDhxYrLLGBC6+7s63FxDOiOQlJafHeHCE0q58IRSIDbs772tDby4Yhtz3q7ixp8vYOaEYr5y6SRGDcnZ93sPz19L5YZd3DZjDA/PX8tPX13L5y8Yn6zDEKGlPUpGWigh02woCCRQzIyJwwYxcdggbptxHI++vo7/+vP7nP/dV7jipDJuOHMUITO+88JKLjqhlC9eNIHqumZ++to6Pn3mKIpyM5J9CJIA7s6etijp4RDpaX3bddoR7aS+uZ265nY6os5xQ3NI6+WItsaWDtbV7qF0UCZD8/r+36CCQAIrPS3EbTOO48qTyvj+S6t5ZmEVc96uIjs9TEF2Ov9+1RTMjLvPG8dz725h9struP/SSUf9uu5OW7STjDRdAd0fNLd1sLmuhT3xAQU5GWkUZEUozE4nFNr/23ddUxvt0U4yI2EyI2HSQnbQN/T2aCdNrR00tUX3/ThORlqYtmgnm+tbGDE4uxf1RdlQu4f0cIjC7MQ0TyoIJPCKB2XytStP4F8+Op45b1fxh8Wb+ZcLxjM4Jx2IzXN09SnlPP7mBs6fVEJORhrRTidkRigEaaEQ9c3tbK5rprqumQmlecycWHLQ60Q7neeWbuEHL61me0Mrc+88i/LCv30grK1pZM7bVXx25tjAT5Ph7vxuUTWNrVE+Ma2816HZ1hH7Fl6YHTnkt++OaCfbGlrZ2dhKOBSirCCLjk6nrqmd6rpm6pvbGTUkh1D8g76hpZ2NO/efCj0tFCIzEiIzEqbTnT2tUVo7okDs7DMrEmZIXjoFWREyI2G2N7SybXcLBVkRBvWgz6mtI8r62j2EQsboIb0/k+gpdRaL9EDVribOffAV2qKdPdr+k6eP5P5LJ5KRFqY92skfFm/mhy+vYfX2RsYMzWH77lbGleTy1D+cQSQcoq6pjSse+gsbapv4/Pnj+OzMsfv21R7t5H+WbOGM44ooGXT4kU5H0twWZXFVHa+sqmH+qhqinc45E4qZOaGYk0cUEg4duv25qa2Dl1fWsLW+hZrGVtzhH2aMoTAemL2xaWcTRbnpZKcf/F20trGVLzzzLn+OzzJbVpDFP503lknZDYw5fhytHZ10xIM4HIJIOERWJLzvm3lTWwfra5voiHaSFg5Rlp/JoKzIvufdnZ172ti2u4Vop1OUm0FxXsa+D1l3Z1dTG1W7minKSWd4QRbt0U7e395IJBxiVFEObR2dtLRHaemI0tIee2zEziZyMsJkp6eRlR7eFyJ7dbqzensj0U5nXEku4dD+H+wNLe3UNrbhgBHrF4i6c9zQ3F59OehtZ7GCQKSHllbXU7WrmXDICBm4Q0enE+10cjPTKCvIonhQBt9/8X0eeXUdJ5bnc8nUYTz2+gaq65oZX5LHnecez8VThvHsu1u468l3uOOc47j7vHHc8PMFvLVuJ5OGD2Ll1gbm/cvZlObHPvT//X+W88ir64iEjatOLuO2GWM4vjjviPVurmvmT8u28sKKbayr2cPOpjZa2mNBlhYyThlZSFrIeGvdTjo6nfysCH83ejCnjynirOOHMK4kd9+H51/X1nLPnCX7vhGnhQwHRhZl89iN06mIN3W4O6u2NfLm2lreWr+T1dsauf3s47jy5LJ9db21bifX/+SvVAzO4uc3TGdE0d/Oil5Yvo0v/uZddje3c++F4xlXkseDf1rJkqp6Hrl8GCUjxnR7rFmRMEW5GYQMqnY1kxY2hg3KZHtDK83tUXIz0oiEQ3S609reSUtHlJyMNIYXZJF1iA/YLfXN1DS0Miw/k7qmdto6Ojm+OJeMbrbf+znak47cprYO1mxvpCA7naF5GYRDRke0ky31LTS2dhAJh4iEDffY/oblZ5KT0bvGGwWBSD/wv0u3cM+vl9DQ2sH00YP5x4+M4exxxfu1Od/3zBKeqtzEjLFDeWVVDd/6P1M5Y0wRM7/zCpdMGcZ3Z53En5dv45bHK7n6lHJyMsI8XbmJlvZOxgzN4dQRhZw6spBzJxRT3OVM4fU1O/jPF97nrfU7gVjT1onlBRTlplOYnc6YoTmceVwReZmxpon65nbmr6rhtfd38Mba2n0f9iOLsvno5FJa26M8/uYGKgqz+dqVJzC1LJ/8rAiVG3Zx6+OVRMIhfnjdKazfsYdfvLmBd6vrARge/wBbU9PI9649mUunDmdNTSNXz36d/KwI9c3thMx45FOnUpCdztf+uJyXV9YwoTSP/7zmJCaUDgJiH7J/Wr6NwrbtjBs/gYy0MGlho9Odzs7YB2ttYxst8SaZnPQ0RhZlkxYO4e7saGxlR2MbBvGzCKMoN538LmcJ3XF3NtQ2sbulPf73kdNnQ4i31DVT09i637pwyCjOy6QoN/2gM4neUhCI9BPVdc3sbGxjSnn3E+A1t0W57AevsXp7IzedNZp/vSzWEf3t59/joXlr+MHfn8yXf7uU8sIsnrn9TDIjYWobW5nzdhUL1u/k7Q272NXUTsjgzOOGcMHkEv60bBuvrd5B6aBMPnnGSD46uZTji3s3h351XTOvrKzh+WVbeX3NDtqjzg1njuLeC8cf1JSzensDn/7ZAqrrmgEYX5LHdaeP4NwJxZQXZtPU1sENP1vAwo27+MZVU/jBvNXsae3gt585i6g7N/78LTbXtdDpTlYkzOfOG8unzhjV7cidw11H4O40tnbQ0h6Nnxn0zRDLaKezcWcTORnhI16AeKDc3FwaGxu7fW7dunVccumlvL7gHTriV68XZB26P6O3FAQiA8iG2j08v2wrN501et+HwJ7WDs558GW2N7SSm5HGH+/60H7XOOzl7ry/vZE/Lt7M7xZtZuPOJgqzI9xxzvFcf/rIPulw3t3STn1T+76mn+5sb2jhsdfX85FxxZw2qvCgb9kNLe1c/9O3WLypjoy0EE/edjqnjCgEYGYvzGYAAAnSSURBVNeeNu59ZglDctP5/PnjDzs0cr8Pt+fug63vHvXx7ad0Clz0//psd4cLgvXr13PppZfum5G0r+mCMpEBZGRRDrfNOG6/dTkZaXzp4ol8/ulF/MfHpnQbAhBrPx5XksfnLxjP3eeP4/3tjQwvyCK3l+3JhzMoM8KgzMM3hxTnZXLPRw99D4i8zAiP3zid+3+/lCtPGr4vBAAKc9J55FPdfjb1O/fddx8VFRXccccdAHz1q18lLS2NefPmsWvXLtrb2/n617/OFVdc0av9trS0cPvtt1NZWUlaWhrf+c53OOecc1i2bBk33ngjbW1tdHZ28swzzzB8+HA+8YlPUFVVRTQa5Stf+QqzZs06+oNz9wH1c+qpp7pIENQ1tSW7hH5l+fLlSX39hQsX+owZM/YtT5w40Tdu3Oj19fXu7l5TU+PHHXecd3Z2urt7Tk7OIfe1bt06nzx5sru7P/jgg37jjTe6u/uKFSu8oqLCm5ub/c477/T//u//dnf31tZWb2pq8jlz5vgtt9yybz91dXXd7r+7vyug0g/xuarZR0X6Kc1t1L+cfPLJbN++nc2bN7N48WIKCwspLS3lS1/6ElOnTuW8886jurqabdu29Wq/r732Gtdffz0AEyZMYOTIkaxatYozzjiDb3zjG3zzm99kw4YNZGVlMWXKFF544QW+8IUv8Oqrr5Kf3zc3YFIQiIj00Mc//nHmzJnDU089xaxZs3jiiSeoqanh7bffZtGiRZSUlNDS0tInr/X3f//3zJ07l6ysLC6++GJeeuklxo0bx8KFC5kyZQr3338/DzzwQJ+8lvoIRER6aNasWdx6663s2LGDV155haeffpri4mIikQjz5s1jw4YNvd7nhz/8YZ544gnOPfdcVq1axcaNGxk/fjxr165lzJgxfPazn2Xjxo0sWbKECRMmMHjwYK6//noKCgr4yU9+0ifHpSAQEemhyZMn09DQQFlZGcOGDeO6667jsssuY8qUKUybNo0JEw7daX4on/nMZ7j99tuZMmUKaWlpPProo2RkZPD000/zi1/8gkgksq8JasGCBdxzzz2EQiEikQizZ8/uk+PS8FERGRB0P4Ke6+3wUfURiIgEnJqGREQS5N133+WTn/zkfusyMjL461//mqSKuqcgEJEBw90TcoeuRJkyZQqLFi06pq/5QZr71TQkIgNCZmYmtbW1H+iDLijcndraWjIzezcvks4IRGRAKC8vp6qqipqammSX0q9lZmZSXl7eq99REIjIgBCJRBg9enSyy0hJCW0aMrMLzWylma02s/u6eT7DzJ6KP/9XMxuVyHpERORgCQsCMwsDDwEXAZOAa83swDt/3wzscvfjge8C30xUPSIi0r1EnhFMB1a7+1p3bwN+BRw4P+sVwGPxx3OAmTaQhgSIiKSARPYRlAGbuixXAX93qG3cvcPM6oEiYEfXjczsNuC2+GKjma38gDUNOXDfARHE4w7iMUMwjzuIxwy9P+6Rh3piQHQWu/vDwMNHux8zqzzUJdapLIjHHcRjhmAedxCPGfr2uBPZNFQNVHRZLo+v63YbM0sD8oHaBNYkIiIHSGQQLADGmtloM0sHrgHmHrDNXODT8cf/B3jJdbWIiMgxlbCmoXib/53A80AY+Jm7LzOzB4jdMm0u8FPgF2a2GthJLCwS6aiblwaoIB53EI8ZgnncQTxm6MPjHnDTUIuISN/SXEMiIgGnIBARCbjABMGRprtIBWZWYWbzzGy5mS0zs8/F1w82sxfM7P34n4XJrrWvmVnYzN4xsz/Gl0fHpy1ZHZ/GJD3ZNfY1Myswszlm9p6ZrTCzMwLyXt8d//e91MyeNLPMVHu/zexnZrbdzJZ2Wdfte2sx34sf+xIzO6W3rxeIIOjhdBepoAP4Z3efBJwO3BE/zvuAF919LPBifDnVfA5Y0WX5m8B349OX7CI2nUmq+S/gf919AnAiseNP6ffazMqAzwLT3P0EYgNRriH13u9HgQsPWHeo9/YiYGz85zag1zcyDkQQ0LPpLgY8d9/i7gvjjxuIfTCUsf9UHo8BVyanwsQws3LgEuAn8WUDziU2bQmk5jHnAzOIjbzD3dvcvY4Uf6/j0oCs+LVH2cAWUuz9dvf5xEZSdnWo9/YK4HGPeRMoMLNhvXm9oARBd9NdlCWplmMiPpPrycBfgRJ33xJ/aitQkqSyEuU/gXuBzvhyEVDn7h3x5VR8v0cDNcDP401iPzGzHFL8vXb3auBBYCOxAKgH3ib132849Ht71J9vQQmCQDGzXOAZ4J/cfXfX5+IX7KXMmGEzuxTY7u5vJ7uWYywNOAWY7e4nA3s4oBko1d5rgHi7+BXEgnA4kMPBTSgpr6/f26AEQU+mu0gJZhYhFgJPuPtv4qu37T1VjP+5PVn1JcBZwOVmtp5Yk9+5xNrOC+JNB5Ca73cVUOXue++CPodYMKTyew1wHrDO3WvcvR34DbF/A6n+fsOh39uj/nwLShD0ZLqLAS/eNv5TYIW7f6fLU12n8vg08PtjXVuiuPsX3b3c3UcRe19fcvfrgHnEpi2BFDtmAHffCmwys/HxVTOB5aTwex23ETjdzLLj/973HndKv99xh3pv5wKfio8eOh2o79KE1DPuHogf4GJgFbAG+HKy60nQMX6I2OniEmBR/OdiYm3mLwLvA38GBie71gQd/9nAH+OPxwBvAauBXwMZya4vAcd7ElAZf79/BxQG4b0G/g14D1gK/ALISLX3G3iSWB9IO7Gzv5sP9d4CRmxU5BrgXWIjqnr1eppiQkQk4ILSNCQiIoegIBARCTgFgYhIwCkIREQCTkEgIhJwCgKRA5hZ1MwWdfnps4nbzGxU1xklRfqDhN2qUmQAa3b3k5JdhMixojMCkR4ys/Vm9i0ze9fM3jKz4+PrR5nZS/G54F80sxHx9SVm9lszWxz/OTO+q7CZPRKfU/9PZpaVtIMSQUEg0p2sA5qGZnV5rt7dpwA/IDbrKcD3gcfcfSrwBPC9+PrvAa+4+4nE5gFaFl8/FnjI3ScDdcDVCT4ekcPSlcUiBzCzRnfP7Wb9euBcd18bn9xvq7sXmdkOYJi7t8fXb3H3IWZWA5S7e2uXfYwCXvDYzUUwsy8AEXf/euKPTKR7OiMQ6R0/xOPeaO3yOIr66iTJFAQivTOry59vxB+/TmzmU4DrgFfjj18Ebod991TOP1ZFivSGvomIHCzLzBZ1Wf5fd987hLTQzJYQ+1Z/bXzdXcTuFHYPsbuG3Rhf/zngYTO7mdg3/9uJzSgp0q+oj0Ckh+J9BNPcfUeyaxHpS2oaEhEJOJ0RiIgEnM4IREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4P5/+4OP4/4XrBkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "test_generator = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('/content/drive/MyDrive/TFM_Máster BDDS/Etiquetas',\n",
        "                                             target_size=(128, 128),\n",
        "                                             batch_size=1,\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset, \n",
        "                                             shuffle=False,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "id": "oGtv6IxJcHyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('img_model.weights.best.hdf5')\n",
        "\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "\n",
        "class_indices = X_train.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "true_classes = X_test.classes"
      ],
      "metadata": {
        "id": "YEDkGv5VdnFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(classifier_svc_pca, '/content/drive/MyDrive/TFM_Máster BDDS/Modelos/modelo_CNN_variedad_features100.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeNRB9fot_2X",
        "outputId": "9b4f01e0-36b2-48b4-edeb-83b9a51a89e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/TFM_Máster BDDS/Modelos/modelo_svm_variedad_features100.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/"
      ],
      "metadata": {
        "id": "1TbOb2YYeSMt"
      }
    }
  ]
}